{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1599d009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = r\"C:\\Users\\KIIT\\Desktop\\Csv\"\n",
    "\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "file_list = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize a list to store the combined data\n",
    "combined_data = []\n",
    "\n",
    "# Iterate over each CSV file and append its data to the combined list\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)  # Read the header\n",
    "        for row in reader:\n",
    "            combined_data.append(row)\n",
    "\n",
    "# Path and filename for the combined CSV file\n",
    "combined_file_path = r\"C:\\Users\\KIIT\\Desktop\\Combined_all.csv\"\n",
    "\n",
    "# Write the combined data to a new CSV file\n",
    "with open(combined_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)  # Write the header\n",
    "    writer.writerows(combined_data)  # Write the data rows\n",
    "\n",
    "print(\"CSV files combined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a71518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac5e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "dataset_path = r\"C:\\Users\\KIIT\\Desktop\\Combined_all.csv\"\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Facies', axis=1)  # Replace 'target_variable' with the actual column name\n",
    "y = df['Facies']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfcacca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9335142469470827\n",
      "F1 Score: 0.9013620216659122\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b423c80",
   "metadata": {},
   "source": [
    "### Custom Simulated Annealing algorithm to perform optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41ed2ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters:\n",
      "n_estimators: 546\n",
      "learning_rate: 0.1962544390489066\n",
      "max_depth: 788\n",
      "min_samples_split: 208\n",
      "min_samples_leaf: 245\n",
      "subsample: 0.9303415851338337\n",
      "Best Parameters: {'n_estimators': 546, 'learning_rate': 0.1962544390489066, 'max_depth': 788, 'min_samples_split': 208, 'min_samples_leaf': 245, 'subsample': 0.9303415851338337}\n",
      "Best Accuracy: 0.9525101763907734\n",
      "Accuracy: 0.9552238805970149\n",
      "F1 Score: 0.9282703317546004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the objective value (e.g., accuracy, F1 score)\n",
    "def calculate_objective_value(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Function to generate a random neighbor solution\n",
    "def generate_neighbor_solution(params, temperature):\n",
    "    neighbor_params = params.copy()\n",
    "    for param_name in params:\n",
    "        value = params[param_name]\n",
    "        if param_name == 'max_depth':\n",
    "            range_min = max(1, value - int(temperature))\n",
    "            range_max = value + int(temperature)\n",
    "            neighbor_params[param_name] = np.random.randint(range_min, range_max + 1)\n",
    "        elif param_name == 'min_samples_leaf':\n",
    "            if isinstance(value, int):\n",
    "                range_min = max(1, value - int(temperature))\n",
    "                range_max = value + int(temperature)\n",
    "                neighbor_params[param_name] = np.random.randint(range_min, range_max + 1)\n",
    "            else:\n",
    "                range_min = max(0.01, value - temperature)\n",
    "                range_max = min(0.5, value + temperature)\n",
    "                neighbor_params[param_name] = round(np.random.uniform(range_min, range_max), 2)\n",
    "        elif isinstance(value, int):\n",
    "            range_min = max(0, value - int(temperature))\n",
    "            range_max = value + int(temperature)\n",
    "            neighbor_params[param_name] = np.random.randint(range_min, range_max + 1)\n",
    "        else:\n",
    "            range_min = max(0.0, value - temperature)\n",
    "            range_max = min(1.0, value + temperature)\n",
    "            neighbor_params[param_name] = np.random.uniform(range_min, range_max)\n",
    "    return neighbor_params\n",
    "\n",
    "# Function to perform Simulated Annealing optimization\n",
    "def perform_simulated_annealing(X_train, X_test, y_train, y_test, initial_params, max_iterations, initial_temperature, cooling_rate):\n",
    "    current_params = initial_params.copy()\n",
    "    current_classifier = GradientBoostingClassifier(**current_params)\n",
    "    current_classifier.fit(X_train, y_train)\n",
    "    current_pred = current_classifier.predict(X_test)\n",
    "    current_value = calculate_objective_value(y_test, current_pred)\n",
    "\n",
    "    best_params = current_params.copy()\n",
    "    best_value = current_value\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        temperature = initial_temperature / (1 + cooling_rate * iteration)\n",
    "\n",
    "        neighbor_params = generate_neighbor_solution(current_params, temperature)\n",
    "        neighbor_classifier = GradientBoostingClassifier(**neighbor_params)\n",
    "        neighbor_classifier.fit(X_train, y_train)\n",
    "        neighbor_pred = neighbor_classifier.predict(X_test)\n",
    "        neighbor_value = calculate_objective_value(y_test, neighbor_pred)\n",
    "\n",
    "        delta_value = neighbor_value - current_value\n",
    "\n",
    "        if delta_value > 0 or np.exp(delta_value / temperature) > np.random.uniform(0, 1):\n",
    "            current_params = neighbor_params\n",
    "            current_classifier = neighbor_classifier\n",
    "            current_pred = neighbor_pred\n",
    "            current_value = neighbor_value\n",
    "\n",
    "        if neighbor_value > best_value:\n",
    "            best_params = neighbor_params\n",
    "            best_value = neighbor_value\n",
    "\n",
    "    return best_params, best_value\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the initial parameters for the gradient boosting classifier\n",
    "initial_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Set the parameters for the Simulated Annealing optimization\n",
    "max_iterations = 100\n",
    "initial_temperature = 100.0\n",
    "cooling_rate = 0.01\n",
    "\n",
    "# Perform Simulated Annealing optimization\n",
    "best_params, best_value = perform_simulated_annealing(X_train, X_test, y_train, y_test, initial_params, max_iterations, initial_temperature, cooling_rate)\n",
    "\n",
    "# Print the optimized parameters\n",
    "print(\"Optimized Parameters:\")\n",
    "for param_name, param_value in best_params.items():\n",
    "    print(f\"{param_name}: {param_value}\")\n",
    "\n",
    "# Create a gradient boosting classifier object with the best parameters\n",
    "gb_classifier = GradientBoostingClassifier(**best_params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the best parameters and the performance metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_value)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d3a7d",
   "metadata": {},
   "source": [
    "### Randomized Search Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f343bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "65 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0832308858067883\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.009320402078782\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0717120953891037\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0717820827209608\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0962536997579244\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0730105547524456\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0132405525564714\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0626484146779251\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0152137276264805\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.033436308079483\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0025529066795666\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.024643330223596\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0872761293149444\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9388996  0.94229634 0.93211016 0.94229288        nan 0.93821876\n",
      " 0.93482662        nan 0.94602975 0.92701908 0.94229461 0.93856234\n",
      " 0.94297373 0.93754194 0.93957757 0.94331329        nan 0.20235562\n",
      " 0.81903255 0.942972   0.93957987 0.94059739 0.93550517 0.94263474\n",
      " 0.81415787        nan 0.26003338 0.67712756 0.92158844 0.32919456\n",
      " 0.69577681 0.22849472 0.35587926 0.94161549 0.94331156        nan\n",
      " 0.28717102 0.30554171 0.93855889 0.89038359 0.64818969 0.94467037\n",
      "        nan 0.94433139 0.9181894  0.92192743 0.92396132 0.9439901\n",
      " 0.4205243  0.94025841 0.92022676        nan 0.94467267 0.89747345\n",
      " 0.30456275 0.93312826 0.38736439 0.28142557        nan        nan\n",
      " 0.94263359 0.94365169 0.93448419 0.9388973  0.25829127        nan\n",
      " 0.94263359 0.89000547 0.93788035 0.90461627 0.92973037 0.94365284\n",
      " 0.90327127 0.94229403        nan 0.48196599 0.94127593 0.54744439\n",
      " 0.94161722 0.43580731 0.9341452  0.94263359 0.93856234 0.9188737\n",
      " 0.60637449 0.93720353 0.93686167        nan 0.92432448 0.92328106\n",
      " 0.94331501 0.60708584 0.93686455 0.94059682 0.38028201        nan\n",
      " 0.93856062 0.91921096 0.75788553 0.28707721]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.13938999080000847, 'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 489, 'subsample': 0.3079416628681888}\n",
      "Accuracy: 0.9497964721845319\n",
      "F1 Score: 0.9213902462885514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter distributions for randomized search\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'max_depth': randint(1, 10),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'subsample': uniform(0.1, 1.0)\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Perform randomized search for hyperparameter optimization\n",
    "random_search = RandomizedSearchCV(gb_classifier, param_distributions, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and its corresponding parameters\n",
    "best_classifier = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Predict on the test set using the best classifier\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the best parameters and the performance metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743dc789",
   "metadata": {},
   "source": [
    "### Grid Search Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a55ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "310 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2508884729488527\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5922115592912176\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5832308858067883\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0504992519695429\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.4331949117361642\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3553614103176526\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0497541333697655\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1208342600258236\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.186751165663848\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.306857343847617\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2510770255019446\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.448913824266084\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0275410183585496\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.139841091301673\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.408120379564417\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.4074401551640625\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2476901205413622\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0110370133182314\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.089452760277563\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.11775135052748\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1414479738275658\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5962536997579244\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0856137535862267\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3209399242521291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5730105547524456\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.102637093105192\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1720041992091832\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.347718773897414\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1722924691708383\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0852798742763157\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1183296523637367\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3024840839871092\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.4670723185801036\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1788648955075587\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.369993553098611\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2601973767177312\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3300393165618185\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.074173829087325\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0646738129396114\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2839637693981412\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2364035974460112\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.420426843771268\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2928903586919394\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.4034809303848486\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1759245752580845\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3545428740846823\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5053819764192635\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.0484455219783197\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3915790437258484\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.026091475046941\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.1133261686923928\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5076937063485463\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.3050843642966599\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.4227903518766931\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.4685991281894601\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.524643330223596\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2293986381352626\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.337100705843019\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.2201325978015367\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.053240846828831\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.32571950838836\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 1.5872761293149444\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.94399125        nan        nan 0.93923973        nan        nan\n",
      " 0.92871572        nan        nan        nan        nan        nan\n",
      " 0.93957757        nan        nan 0.92124255 0.94025899        nan\n",
      "        nan 0.93652499        nan        nan        nan        nan\n",
      " 0.93720181 0.94297315 0.94127709 0.94025668        nan        nan\n",
      " 0.9409381  0.93889845 0.94229116 0.94263417        nan        nan\n",
      "        nan 0.94093695 0.93889845 0.94467037        nan 0.94568904\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94433081        nan        nan        nan 0.94263474\n",
      "        nan 0.93856119        nan 0.94568789 0.94195563 0.90664269\n",
      " 0.94229288        nan        nan 0.93516618        nan        nan\n",
      " 0.94093695        nan        nan 0.93618313        nan 0.94263302\n",
      "        nan        nan        nan 0.93923973        nan 0.93788092\n",
      "        nan        nan        nan 0.94229634 0.93992           nan\n",
      "        nan        nan        nan 0.94466979        nan        nan\n",
      "        nan        nan        nan        nan 0.94297373        nan\n",
      " 0.935843          nan 0.94059567        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.23421207149312367, 'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 5, 'n_estimators': 260, 'subsample': 0.6180753636155208}\n",
      "Accuracy: 0.9538670284938942\n",
      "F1 Score: 0.9254729681878515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter distributions for random search\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'subsample': uniform(0.6, 1.0)\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Perform random search for hyperparameter optimization\n",
    "random_search = RandomizedSearchCV(gb_classifier, param_distributions, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and its corresponding parameters\n",
    "best_classifier = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Predict on the test set using the best classifier\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the best parameters and the performance metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674295c6",
   "metadata": {},
   "source": [
    "### bayes search optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbade674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict([('learning_rate', 0.021698784649126786), ('max_depth', 10), ('min_samples_leaf', 10), ('min_samples_split', 11), ('n_estimators', 1000), ('subsample', 0.6412325151785777)])\n",
      "Accuracy: 0.9484396200814111\n",
      "F1 Score: 0.9179586829313171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the search space for Bayesian optimization\n",
    "param_space = {\n",
    "    'n_estimators': (100, 1000),\n",
    "    'learning_rate': (0.01, 0.5, 'log-uniform'),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 10),\n",
    "    'subsample': (0.6, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Perform Bayesian optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(gb_classifier, param_space, n_iter=100, cv=5, scoring='accuracy')\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and its corresponding parameters\n",
    "best_classifier = bayes_search.best_estimator_\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Predict on the test set using the best classifier\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the best parameters and the performance metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13c6f9",
   "metadata": {},
   "source": [
    "### Best parameters \n",
    "##### 1. simulated annealing\n",
    "##### Best Parameters: {'n_estimators': 97, 'learning_rate': 0.18581554614968288, 'max_depth': 83, 'min_samples_split': 120, 'min_samples_leaf': 74, 'subsample': 0.21483960974576843}\n",
    "##### Best Accuracy: 0.9565807327001357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c870c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9443690637720489\n",
      "F1 Score: 0.9109112575985641\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 97,\n",
    "    'learning_rate':  0.18581554614968288,\n",
    "    'max_depth': 83,\n",
    "    'min_samples_split': 120,\n",
    "    'min_samples_leaf': 74,\n",
    "    'subsample': 0.21483960974576843\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd4267",
   "metadata": {},
   "source": [
    "##### 2. Grid Search\n",
    "##### Best Parameters: {'learning_rate': 0.23421207149312367, 'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 5, 'n_estimators': 260, 'subsample': 0.6180753636155208}\n",
    "##### Accuracy: 0.9538670284938942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba749e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9525101763907734\n",
      "F1 Score: 0.9241244916869189\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 260,\n",
    "    'learning_rate':  0.23421207149312367,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 9,\n",
    "    'subsample': 0.6180753636155208\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a713fa",
   "metadata": {},
   "source": [
    "### Combining 4 csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f818bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = r\"C:\\Users\\KIIT\\Desktop\\Csv\"\n",
    "\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "file_list = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize a list to store the combined data\n",
    "combined_data = []\n",
    "\n",
    "# Iterate over each CSV file and append its data to the combined list\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)  # Read the header\n",
    "        for row in reader:\n",
    "            combined_data.append(row)\n",
    "\n",
    "# Path and filename for the combined CSV file\n",
    "combined_file_path = r\"C:\\Users\\KIIT\\Desktop\\Combined_4.csv\"\n",
    "\n",
    "# Write the combined data to a new CSV file\n",
    "with open(combined_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)  # Write the header\n",
    "    writer.writerows(combined_data)  # Write the data rows\n",
    "\n",
    "print(\"CSV files combined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ab2c5",
   "metadata": {},
   "source": [
    "##### 1. simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fa85c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7868480725623582\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the training data from the first CSV file\n",
    "train_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\Combined_4.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_train = train_data.drop('Facies', axis=1)\n",
    "y_train = train_data['Facies']\n",
    "\n",
    "# Load the test data from the second CSV file\n",
    "test_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\SB-19.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_test = test_data.drop('Facies', axis=1)\n",
    "y_test = test_data['Facies']\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 97,\n",
    "    'learning_rate':  0.18581554614968288,\n",
    "    'max_depth': 83,\n",
    "    'min_samples_split': 120,\n",
    "    'min_samples_leaf': 74,\n",
    "    'subsample': 0.21483960974576843\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337902d6",
   "metadata": {},
   "source": [
    "##### 2. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4714830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7936507936507936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the training data from the first CSV file\n",
    "train_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\Combined_4.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_train = train_data.drop('Facies', axis=1)\n",
    "y_train = train_data['Facies']\n",
    "\n",
    "# Load the test data from the second CSV file\n",
    "test_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\SB-19.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_test = test_data.drop('Facies', axis=1)\n",
    "y_test = test_data['Facies']\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 260,\n",
    "    'learning_rate':  0.23421207149312367,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 9,\n",
    "    'subsample': 0.6180753636155208\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7373204",
   "metadata": {},
   "source": [
    "##### 3. Randomized Search\n",
    "##### Best Parameters: {'learning_rate': 0.13938999080000847, 'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 489, 'subsample': 0.3079416628681888}\n",
    "##### Accuracy: 0.9497964721845319\n",
    "##### F1 Score: 0.9213902462885514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17982363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7437641723356009\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the training data from the first CSV file\n",
    "train_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\Combined_4.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_train = train_data.drop('Facies', axis=1)\n",
    "y_train = train_data['Facies']\n",
    "\n",
    "# Load the test data from the second CSV file\n",
    "test_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\SB-19.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_test = test_data.drop('Facies', axis=1)\n",
    "y_test = test_data['Facies']\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 3,\n",
    "    'learning_rate': 0.13938999080000847,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_split': 3,\n",
    "    'min_samples_leaf': 4,\n",
    "    'subsample': 0.3079416628681888\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c58e4d",
   "metadata": {},
   "source": [
    "##### Sinulated Annealing part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32d4215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7573696145124716\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the training data from the first CSV file\n",
    "train_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\Combined_4.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_train = train_data.drop('Facies', axis=1)\n",
    "y_train = train_data['Facies']\n",
    "\n",
    "# Load the test data from the second CSV file\n",
    "test_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\SB-19.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_test = test_data.drop('Facies', axis=1)\n",
    "y_test = test_data['Facies']\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 546,\n",
    "    'learning_rate': 0.1962544390489066,\n",
    "    'max_depth': 788,\n",
    "    'min_samples_split': 208,\n",
    "    'min_samples_leaf': 245, \n",
    "    'subsample': 0.9303415851338337\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f07f5",
   "metadata": {},
   "source": [
    "##### Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "731ba43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7913832199546486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the training data from the first CSV file\n",
    "train_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\Combined_4.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_train = train_data.drop('Facies', axis=1)\n",
    "y_train = train_data['Facies']\n",
    "\n",
    "# Load the test data from the second CSV file\n",
    "test_data = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\SB-19.csv\")\n",
    "\n",
    "# Split the features and target variable\n",
    "X_test = test_data.drop('Facies', axis=1)\n",
    "y_test = test_data['Facies']\n",
    "\n",
    "# Define the parameters for the gradient boosting classifier\n",
    "params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.021698784649126786,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 11,\n",
    "    'min_samples_leaf': 10, \n",
    "    'subsample': 0.6412325151785777\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object with the defined parameters\n",
    "gb_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d689807",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2736\\2377193393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Perform Bayesian optimization for hyperparameter tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mbayes_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mbayes_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Get the best estimator and its corresponding parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_kwargs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;31m# BaseSearchCV never ranked train scores,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                 optim_result = self._step(\n\u001b[0m\u001b[0;32m    513\u001b[0m                     \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                     \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpoint_asdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         \u001b[0mall_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         \u001b[1;31m# Feed the point and objective value back into optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;31m# Optimizer minimizes objective, hence provide negative score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = r\"C:\\Users\\KIIT\\Desktop\\Final\\Combined_12.csv\"\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Facies', axis=1)  # Replace 'target_variable' with the actual column name\n",
    "y = df['Facies']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the search space for Bayesian optimization\n",
    "param_space = {\n",
    "    'n_estimators': (100, 1000),\n",
    "    'learning_rate': (0.01, 0.9999999999, 'log-uniform'),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 10),\n",
    "    'subsample': (0.1, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Create a gradient boosting classifier object\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Perform Bayesian optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(gb_classifier, param_space, n_iter=100, cv=5, scoring='accuracy')\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and its corresponding parameters\n",
    "best_classifier = bayes_search.best_estimator_\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "end= time.time()\n",
    "print(f\"time:{end-start}\")\n",
    "\n",
    "# Predict on the test set using the best classifier\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the best parameters and the performance metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef682eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
